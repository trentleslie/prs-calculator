{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRS Methodology Experiment: pgsc_calc vs Custom Script\n",
    "\n",
    "**Objective**: Compare two PRS calculation approaches across different reference genomes and evaluate ancestry correction behavior.\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "### Overview\n",
    "\n",
    "This experiment systematically compares:\n",
    "\n",
    "1. **Two VCF files** (different reference genomes)\n",
    "   - Trent's WGS: GRCh38 (from Nucleus)\n",
    "   - Rowen's WGS: GRCh37/hg19 (from GATK 3.3 pipeline)\n",
    "\n",
    "2. **Two calculation methods**\n",
    "   - **pgsc_calc**: Nextflow pipeline with ancestry normalization\n",
    "   - **Custom Script**: Reference genome lookup for homozygous reference sites\n",
    "\n",
    "3. **Two normalization states**\n",
    "   - Raw scores (before ancestry correction)\n",
    "   - Normalized scores (after ancestry correction)\n",
    "\n",
    "### Key Questions\n",
    "\n",
    "1. How does pgsc_calc handle WGS data vs array-imputed data?\n",
    "2. What is the magnitude of the \"homozygous reference bias\" in pgsc_calc for WGS?\n",
    "3. Does ancestry normalization correct or amplify this bias?\n",
    "4. Are the custom script's \"adjusted\" scores comparable to pgsc_calc's normalized scores?\n",
    "\n",
    "### Critical Context from Literature\n",
    "\n",
    "Per [Lambert et al. 2024](https://doi.org/10.1101/2024.05.29.24307783):\n",
    "> \"The current PGS Catalog Calculator is optimized to calculate PGS on imputed genotypes derived from genotyping array data; however, a common user request is to support whole-genome sequencing data (unimputed VCFs).\"\n",
    "\n",
    "This means pgsc_calc may **systematically underestimate** scores for WGS data when the effect allele equals the reference allele at positions not in the VCF (homozygous reference sites)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Matrix\n",
    "\n",
    "| Sample | Reference Build | Method | Normalization | Output ID |\n",
    "|--------|-----------------|--------|---------------|----------|\n",
    "| Trent | GRCh38 | pgsc_calc | Raw | T_pgsc_raw |\n",
    "| Trent | GRCh38 | pgsc_calc | Ancestry-adjusted | T_pgsc_adj |\n",
    "| Trent | GRCh38 | Custom | Unadjusted (VCF only) | T_custom_unadj |\n",
    "| Trent | GRCh38 | Custom | Adjusted (+ ref lookup) | T_custom_adj |\n",
    "| Rowen | GRCh37 | pgsc_calc | Raw | R_pgsc_raw |\n",
    "| Rowen | GRCh37 | pgsc_calc | Ancestry-adjusted | R_pgsc_adj |\n",
    "| Rowen | GRCh37 | Custom | Unadjusted (VCF only) | R_custom_unadj |\n",
    "| Rowen | GRCh37 | Custom | Adjusted (+ ref lookup) | R_custom_adj |\n",
    "\n",
    "### PGS Scores to Compare\n",
    "\n",
    "| PGS ID | Trait | Method | Variants | Notes |\n",
    "|--------|-------|--------|----------|-------|\n",
    "| PGS002308 | Type 2 Diabetes | PRS-CSx | ~1.26M | High clinical relevance |\n",
    "| PGS004034 | Alzheimer's Disease | LDpred2-auto | ~1.05M | |\n",
    "| PGS000027 | BMI | LDpred | ~2.10M | Largest variant count |\n",
    "| PGS004237 | CAD | LDpred | ~1.15M | |\n",
    "| PGS004696 | CHD | PRS-CSx | ~1.29M | New addition |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.341867Z",
     "iopub.status.busy": "2026-02-08T22:34:36.341692Z",
     "iopub.status.idle": "2026-02-08T22:34:36.822712Z",
     "shell.execute_reply": "2026-02-08T22:34:36.822028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment base directory: /home/trentleslie/Documents/Trent's Vault/Active ðŸŽ¯/Personal/Health/Nucleus/Analysis/PRS\n",
      "Results will be saved to: /home/trentleslie/Documents/Trent's Vault/Active ðŸŽ¯/Personal/Health/Nucleus/Analysis/PRS/results/methodology_comparison\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import gzip\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuration\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Configuration for the PRS methodology experiment.\"\"\"\n",
    "    base_dir: Path = Path('.')  # Adjust to your working directory\n",
    "    \n",
    "    # VCF files\n",
    "    trent_vcf: str = 'data/trent/NU-UMMI-7887.vcf.gz'  # GRCh38\n",
    "    rowan_vcf: str = 'data/rowan/LR_full_variant_file.vcf.gz'  # GRCh37\n",
    "    \n",
    "    # Reference genomes\n",
    "    ref_grch38: str = 'reference/Homo_sapiens_assembly38.fasta'\n",
    "    ref_grch37: str = 'reference/Homo_sapiens_assembly19.fasta'\n",
    "    \n",
    "    # PGS IDs to analyze\n",
    "    pgs_ids: tuple = ('PGS002308', 'PGS004034', 'PGS000027', 'PGS004237', 'PGS004696')\n",
    "    \n",
    "    # Output directories\n",
    "    results_dir: Path = Path('results/methodology_comparison')\n",
    "    \n",
    "config = ExperimentConfig()\n",
    "config.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Experiment base directory: {config.base_dir.absolute()}\")\n",
    "print(f\"Results will be saved to: {config.results_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Data Preparation\n",
    "\n",
    "### 1.1 Download Harmonized Scoring Files\n",
    "\n",
    "Both GRCh37 and GRCh38 harmonized files are needed for proper comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.844757Z",
     "iopub.status.busy": "2026-02-08T22:34:36.844525Z",
     "iopub.status.idle": "2026-02-08T22:34:36.848772Z",
     "shell.execute_reply": "2026-02-08T22:34:36.848050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RUN THESE COMMANDS TO DOWNLOAD SCORING FILES:\n",
      "======================================================================\n",
      "# Create scores directory\n",
      "mkdir -p scores\n",
      "\n",
      "# GRCh37 Harmonized Files\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS002308/ScoringFiles/Harmonized/PGS002308_hmPOS_GRCh37.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS004034/ScoringFiles/Harmonized/PGS004034_hmPOS_GRCh37.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS000027/ScoringFiles/Harmonized/PGS000027_hmPOS_GRCh37.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS004237/ScoringFiles/Harmonized/PGS004237_hmPOS_GRCh37.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS004696/ScoringFiles/Harmonized/PGS004696_hmPOS_GRCh37.txt.gz' -P scores/\n",
      "\n",
      "# GRCh38 Harmonized Files\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS002308/ScoringFiles/Harmonized/PGS002308_hmPOS_GRCh38.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS004034/ScoringFiles/Harmonized/PGS004034_hmPOS_GRCh38.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS000027/ScoringFiles/Harmonized/PGS000027_hmPOS_GRCh38.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS004237/ScoringFiles/Harmonized/PGS004237_hmPOS_GRCh38.txt.gz' -P scores/\n",
      "wget -nc 'https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/PGS004696/ScoringFiles/Harmonized/PGS004696_hmPOS_GRCh38.txt.gz' -P scores/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate download commands for scoring files\n",
    "def generate_download_commands(pgs_ids: tuple, builds: tuple = ('GRCh37', 'GRCh38')) -> str:\n",
    "    \"\"\"Generate wget commands for downloading PGS scoring files.\"\"\"\n",
    "    commands = [\"# Create scores directory\", \"mkdir -p scores\", \"\"]\n",
    "    \n",
    "    for build in builds:\n",
    "        commands.append(f\"# {build} Harmonized Files\")\n",
    "        for pgs_id in pgs_ids:\n",
    "            url = f\"https://ftp.ebi.ac.uk/pub/databases/spot/pgs/scores/{pgs_id}/ScoringFiles/Harmonized/{pgs_id}_hmPOS_{build}.txt.gz\"\n",
    "            commands.append(f\"wget -nc '{url}' -P scores/\")\n",
    "        commands.append(\"\")\n",
    "    \n",
    "    return \"\\n\".join(commands)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"RUN THESE COMMANDS TO DOWNLOAD SCORING FILES:\")\n",
    "print(\"=\" * 70)\n",
    "print(generate_download_commands(config.pgs_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Verify VCF Files and Reference Genomes\n",
    "\n",
    "Check that all required files exist and validate their formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.850121Z",
     "iopub.status.busy": "2026-02-08T22:34:36.850010Z",
     "iopub.status.idle": "2026-02-08T22:34:36.875072Z",
     "shell.execute_reply": "2026-02-08T22:34:36.874335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCF File Validation\n",
      "==================================================\n",
      "\n",
      "Trent (GRCh38):\n",
      "  Path: data/trent/NU-UMMI-7887.vcf.gz\n",
      "  Exists: True\n",
      "  Sample ID: 093025-WGS-C3330185\n",
      "  Reference: file:///data/scratch/hg38_altmaskedv2-cnv-hla-graph-anchored.v8/reference.bin\n",
      "  Contig format: chr_prefix\n",
      "\n",
      "Rowen (GRCh37):\n",
      "  Path: data/rowan/LR_full_variant_file.vcf.gz\n",
      "  Exists: True\n",
      "  Sample ID: A115AW807-006\n",
      "  Reference: file:///home/dnanexus/genome.fa\n",
      "  Contig format: numeric\n"
     ]
    }
   ],
   "source": [
    "def check_vcf_header(vcf_path: str) -> dict:\n",
    "    \"\"\"Extract key information from VCF header.\"\"\"\n",
    "    info = {\n",
    "        'path': vcf_path,\n",
    "        'exists': Path(vcf_path).exists(),\n",
    "        'reference': None,\n",
    "        'sample_id': None,\n",
    "        'contig_format': None  # 'chr' prefix or numeric\n",
    "    }\n",
    "    \n",
    "    if not info['exists']:\n",
    "        return info\n",
    "    \n",
    "    opener = gzip.open if vcf_path.endswith('.gz') else open\n",
    "    try:\n",
    "        with opener(vcf_path, 'rt') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('##reference='):\n",
    "                    info['reference'] = line.strip().split('=', 1)[1]\n",
    "                elif line.startswith('##contig='):\n",
    "                    # Check if contigs use 'chr' prefix\n",
    "                    if 'ID=chr' in line:\n",
    "                        info['contig_format'] = 'chr_prefix'\n",
    "                    elif 'ID=1' in line or 'ID=2' in line:\n",
    "                        info['contig_format'] = 'numeric'\n",
    "                elif line.startswith('#CHROM'):\n",
    "                    headers = line.strip().split('\\t')\n",
    "                    if len(headers) > 9:\n",
    "                        info['sample_id'] = headers[9]\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        info['error'] = str(e)\n",
    "    \n",
    "    return info\n",
    "\n",
    "# Check VCF files\n",
    "print(\"VCF File Validation\")\n",
    "print(\"=\" * 50)\n",
    "for name, vcf_path in [('Trent (GRCh38)', config.trent_vcf), ('Rowen (GRCh37)', config.rowan_vcf)]:\n",
    "    info = check_vcf_header(vcf_path)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Path: {info['path']}\")\n",
    "    print(f\"  Exists: {info['exists']}\")\n",
    "    if info['exists']:\n",
    "        print(f\"  Sample ID: {info['sample_id']}\")\n",
    "        print(f\"  Reference: {info['reference']}\")\n",
    "        print(f\"  Contig format: {info['contig_format']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Convert VCF to PLINK2 Format (for pgsc_calc)\n",
    "\n",
    "pgsc_calc works best with PLINK2 format (pgen/pvar/psam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.876989Z",
     "iopub.status.busy": "2026-02-08T22:34:36.876786Z",
     "iopub.status.idle": "2026-02-08T22:34:36.903396Z",
     "shell.execute_reply": "2026-02-08T22:34:36.902809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PLINK2 CONVERSION COMMANDS\n",
      "======================================================================\n",
      "\n",
      "# Trent (GRCh38)\n",
      "# Convert Trent VCF to PLINK2 format\n",
      "plink2 --vcf data/trent/NU-UMMI-7887.vcf.gz \\\n",
      "    --make-pgen \\\n",
      "    --out data/trent/trent_plink2 \\\n",
      "    --allow-extra-chr \\\n",
      "    --max-alleles 2\n",
      "\n",
      "# Verify output files exist\n",
      "ls -la data/trent/trent_plink2.*\n",
      "\n",
      "# Rowen (GRCh37)\n",
      "# Convert Rowen VCF to PLINK2 format\n",
      "plink2 --vcf data/rowan/LR_full_variant_file.vcf.gz \\\n",
      "    --make-pgen \\\n",
      "    --out data/rowan/rowan_plink2 \\\n",
      "    --allow-extra-chr \\\n",
      "    --max-alleles 2\n",
      "\n",
      "# Verify output files exist\n",
      "ls -la data/rowan/rowan_plink2.*\n"
     ]
    }
   ],
   "source": [
    "def generate_plink_conversion_commands(sample_name: str, vcf_path: str, output_prefix: str) -> str:\n",
    "    \"\"\"Generate PLINK2 commands for VCF to pgen conversion.\"\"\"\n",
    "    commands = f\"\"\"\n",
    "# Convert {sample_name} VCF to PLINK2 format\n",
    "plink2 --vcf {vcf_path} \\\\\n",
    "    --make-pgen \\\\\n",
    "    --out {output_prefix} \\\\\n",
    "    --allow-extra-chr \\\\\n",
    "    --max-alleles 2\n",
    "\n",
    "# Verify output files exist\n",
    "ls -la {output_prefix}.*\n",
    "\"\"\"\n",
    "    return commands.strip()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PLINK2 CONVERSION COMMANDS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n# Trent (GRCh38)\")\n",
    "print(generate_plink_conversion_commands('Trent', config.trent_vcf, 'data/trent/trent_plink2'))\n",
    "\n",
    "print(\"\\n# Rowen (GRCh37)\")\n",
    "print(generate_plink_conversion_commands('Rowen', config.rowan_vcf, 'data/rowan/rowan_plink2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Run Calculations\n",
    "\n",
    "### 2.1 Custom Script Calculations\n",
    "\n",
    "The custom script calculates both adjusted (with reference lookup) and unadjusted (VCF-only) scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.905061Z",
     "iopub.status.busy": "2026-02-08T22:34:36.904866Z",
     "iopub.status.idle": "2026-02-08T22:34:36.926941Z",
     "shell.execute_reply": "2026-02-08T22:34:36.926379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CUSTOM SCRIPT COMMANDS\n",
      "======================================================================\n",
      "# Custom Script Calculations for Trent (GRCh38)\n",
      "mkdir -p results/methodology_comparison/custom/trent\n",
      "\n",
      "# PGS002308\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS002308_hmPOS_GRCh38.txt.gz \\\n",
      "    --vcf data/trent/NU-UMMI-7887.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly38.fasta \\\n",
      "    --build GRCh38 \\\n",
      "    --output results/methodology_comparison/custom/trent/PGS002308\n",
      "# PGS004034\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS004034_hmPOS_GRCh38.txt.gz \\\n",
      "    --vcf data/trent/NU-UMMI-7887.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly38.fasta \\\n",
      "    --build GRCh38 \\\n",
      "    --output results/methodology_comparison/custom/trent/PGS004034\n",
      "# PGS000027\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS000027_hmPOS_GRCh38.txt.gz \\\n",
      "    --vcf data/trent/NU-UMMI-7887.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly38.fasta \\\n",
      "    --build GRCh38 \\\n",
      "    --output results/methodology_comparison/custom/trent/PGS000027\n",
      "# PGS004237\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS004237_hmPOS_GRCh38.txt.gz \\\n",
      "    --vcf data/trent/NU-UMMI-7887.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly38.fasta \\\n",
      "    --build GRCh38 \\\n",
      "    --output results/methodology_comparison/custom/trent/PGS004237\n",
      "# PGS004696\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS004696_hmPOS_GRCh38.txt.gz \\\n",
      "    --vcf data/trent/NU-UMMI-7887.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly38.fasta \\\n",
      "    --build GRCh38 \\\n",
      "    --output results/methodology_comparison/custom/trent/PGS004696\n",
      "\n",
      "\n",
      "# Custom Script Calculations for Rowen (GRCh37)\n",
      "mkdir -p results/methodology_comparison/custom/rowan\n",
      "\n",
      "# PGS002308\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS002308_hmPOS_GRCh37.txt.gz \\\n",
      "    --vcf data/rowan/LR_full_variant_file.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly19.fasta \\\n",
      "    --build GRCh37 \\\n",
      "    --output results/methodology_comparison/custom/rowan/PGS002308\n",
      "# PGS004034\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS004034_hmPOS_GRCh37.txt.gz \\\n",
      "    --vcf data/rowan/LR_full_variant_file.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly19.fasta \\\n",
      "    --build GRCh37 \\\n",
      "    --output results/methodology_comparison/custom/rowan/PGS004034\n",
      "# PGS000027\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS000027_hmPOS_GRCh37.txt.gz \\\n",
      "    --vcf data/rowan/LR_full_variant_file.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly19.fasta \\\n",
      "    --build GRCh37 \\\n",
      "    --output results/methodology_comparison/custom/rowan/PGS000027\n",
      "# PGS004237\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS004237_hmPOS_GRCh37.txt.gz \\\n",
      "    --vcf data/rowan/LR_full_variant_file.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly19.fasta \\\n",
      "    --build GRCh37 \\\n",
      "    --output results/methodology_comparison/custom/rowan/PGS004237\n",
      "# PGS004696\n",
      "python src/pgs_calculator.py \\\n",
      "    --pgs-file scores/PGS004696_hmPOS_GRCh37.txt.gz \\\n",
      "    --vcf data/rowan/LR_full_variant_file.vcf.gz \\\n",
      "    --reference reference/Homo_sapiens_assembly19.fasta \\\n",
      "    --build GRCh37 \\\n",
      "    --output results/methodology_comparison/custom/rowan/PGS004696\n"
     ]
    }
   ],
   "source": [
    "def generate_custom_script_commands(\n",
    "    sample_name: str,\n",
    "    vcf_path: str,\n",
    "    ref_path: str,\n",
    "    build: str,\n",
    "    output_prefix: str,\n",
    "    pgs_ids: tuple\n",
    ") -> str:\n",
    "    \"\"\"Generate commands for running the custom PGS calculator.\"\"\"\n",
    "    commands = [f\"# Custom Script Calculations for {sample_name} ({build})\"]\n",
    "    commands.append(f\"mkdir -p {output_prefix}\")\n",
    "    commands.append(\"\")\n",
    "    \n",
    "    for pgs_id in pgs_ids:\n",
    "        pgs_file = f\"scores/{pgs_id}_hmPOS_{build}.txt.gz\"\n",
    "        cmd = f\"\"\"\n",
    "# {pgs_id}\n",
    "python src/pgs_calculator.py \\\\\n",
    "    --pgs-file {pgs_file} \\\\\n",
    "    --vcf {vcf_path} \\\\\n",
    "    --reference {ref_path} \\\\\n",
    "    --build {build} \\\\\n",
    "    --output {output_prefix}/{pgs_id}\n",
    "\"\"\"\n",
    "        commands.append(cmd.strip())\n",
    "    \n",
    "    return \"\\n\".join(commands)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CUSTOM SCRIPT COMMANDS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(generate_custom_script_commands(\n",
    "    'Trent', config.trent_vcf, config.ref_grch38, 'GRCh38',\n",
    "    'results/methodology_comparison/custom/trent', config.pgs_ids\n",
    "))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(generate_custom_script_commands(\n",
    "    'Rowen', config.rowan_vcf, config.ref_grch37, 'GRCh37',\n",
    "    'results/methodology_comparison/custom/rowan', config.pgs_ids\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 pgsc_calc Pipeline Execution\n",
    "\n",
    "pgsc_calc provides both raw scores and ancestry-normalized scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.928267Z",
     "iopub.status.busy": "2026-02-08T22:34:36.928100Z",
     "iopub.status.idle": "2026-02-08T22:34:36.943180Z",
     "shell.execute_reply": "2026-02-08T22:34:36.942365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "pgsc_calc COMMANDS\n",
      "======================================================================\n",
      "# pgsc_calc for Trent (GRCh38)\n",
      "# Create samplesheet\n",
      "cat > config/trent_samplesheet.csv << 'EOF'\n",
      "sampleset,path_prefix,chrom,format\n",
      "trent,data/trent/trent_plink2,,pfile\n",
      "EOF\n",
      "\n",
      "# Run pgsc_calc with ancestry normalization\n",
      "nextflow run pgscatalog/pgsc_calc \\\n",
      "    -profile conda \\\n",
      "    --input config/trent_samplesheet.csv \\\n",
      "    --pgs_id PGS002308,PGS004034,PGS000027,PGS004237,PGS004696 \\\n",
      "    --target_build GRCh38 \\\n",
      "    --ancestry_panel hgdp_1kgp \\\n",
      "    --ancestry_normalization true \\\n",
      "    --outdir results/methodology_comparison/pgsc_calc/trent \\\n",
      "    -resume\n",
      "\n",
      "\n",
      "# pgsc_calc for Rowen (GRCh37)\n",
      "# Create samplesheet\n",
      "cat > config/rowan_samplesheet.csv << 'EOF'\n",
      "sampleset,path_prefix,chrom,format\n",
      "rowen,data/rowen/rowen_plink2,,pfile\n",
      "EOF\n",
      "\n",
      "# Run pgsc_calc with ancestry normalization\n",
      "nextflow run pgscatalog/pgsc_calc \\\n",
      "    -profile conda \\\n",
      "    --input config/rowan_samplesheet.csv \\\n",
      "    --pgs_id PGS002308,PGS004034,PGS000027,PGS004237,PGS004696 \\\n",
      "    --target_build GRCh37 \\\n",
      "    --ancestry_panel hgdp_1kgp \\\n",
      "    --ancestry_normalization true \\\n",
      "    --outdir results/methodology_comparison/pgsc_calc/rowan \\\n",
      "    -resume\n"
     ]
    }
   ],
   "source": [
    "def generate_samplesheet(sample_name: str, plink_prefix: str, build: str) -> str:\n",
    "    \"\"\"Generate samplesheet CSV content for pgsc_calc.\"\"\"\n",
    "    return f\"\"\"sampleset,path_prefix,chrom,format\n",
    "{sample_name.lower()},{plink_prefix},,pfile\n",
    "\"\"\"\n",
    "\n",
    "def generate_pgsc_calc_command(\n",
    "    sample_name: str,\n",
    "    samplesheet: str,\n",
    "    pgs_ids: tuple,\n",
    "    build: str,\n",
    "    output_dir: str,\n",
    "    ancestry_panel: str = 'hgdp_1kgp'\n",
    ") -> str:\n",
    "    \"\"\"Generate pgsc_calc Nextflow command.\"\"\"\n",
    "    pgs_id_str = ','.join(pgs_ids)\n",
    "    \n",
    "    cmd = f\"\"\"\n",
    "# pgsc_calc for {sample_name} ({build})\n",
    "# Create samplesheet\n",
    "cat > {samplesheet} << 'EOF'\n",
    "{generate_samplesheet(sample_name, f'data/{sample_name.lower()}/{sample_name.lower()}_plink2', build)}EOF\n",
    "\n",
    "# Run pgsc_calc with ancestry normalization\n",
    "nextflow run pgscatalog/pgsc_calc \\\\\n",
    "    -profile conda \\\\\n",
    "    --input {samplesheet} \\\\\n",
    "    --pgs_id {pgs_id_str} \\\\\n",
    "    --target_build {build} \\\\\n",
    "    --ancestry_panel {ancestry_panel} \\\\\n",
    "    --ancestry_normalization true \\\\\n",
    "    --outdir {output_dir} \\\\\n",
    "    -resume\n",
    "\"\"\"\n",
    "    return cmd.strip()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"pgsc_calc COMMANDS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(generate_pgsc_calc_command(\n",
    "    'Trent', 'config/trent_samplesheet.csv', config.pgs_ids, 'GRCh38',\n",
    "    'results/methodology_comparison/pgsc_calc/trent'\n",
    "))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(generate_pgsc_calc_command(\n",
    "    'Rowen', 'config/rowan_samplesheet.csv', config.pgs_ids, 'GRCh37',\n",
    "    'results/methodology_comparison/pgsc_calc/rowan'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Result Loading and Comparison\n",
    "\n",
    "### 3.1 Load Results from Both Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.944420Z",
     "iopub.status.busy": "2026-02-08T22:34:36.944205Z",
     "iopub.status.idle": "2026-02-08T22:34:36.969752Z",
     "shell.execute_reply": "2026-02-08T22:34:36.969021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result loading functions defined.\n",
      "Run the calculation commands above, then continue with Phase 3.2.\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class PRSResult:\n",
    "    \"\"\"Container for PRS calculation results.\"\"\"\n",
    "    sample: str\n",
    "    pgs_id: str\n",
    "    method: str  # 'custom' or 'pgsc_calc'\n",
    "    build: str\n",
    "    \n",
    "    # Raw scores\n",
    "    raw_score: float\n",
    "    unadjusted_score: Optional[float] = None  # Custom script only (VCF-only)\n",
    "    adjusted_score: Optional[float] = None    # Custom script only (+ ref lookup)\n",
    "    \n",
    "    # Normalized scores (pgsc_calc only)\n",
    "    z_score: Optional[float] = None\n",
    "    percentile: Optional[float] = None\n",
    "    ancestry_population: Optional[str] = None\n",
    "    \n",
    "    # Coverage metrics\n",
    "    variants_total: Optional[int] = None\n",
    "    variants_matched: Optional[int] = None\n",
    "    variants_from_vcf: Optional[int] = None\n",
    "    variants_from_ref: Optional[int] = None\n",
    "    coverage_pct: Optional[float] = None\n",
    "\n",
    "\n",
    "def load_custom_script_results(results_dir: Path, sample: str, pgs_id: str, build: str) -> Optional[PRSResult]:\n",
    "    \"\"\"Load results from custom script output.\"\"\"\n",
    "    # Look for summary file\n",
    "    summary_pattern = f\"{pgs_id}*summary*.txt\"\n",
    "    summary_files = list(results_dir.glob(summary_pattern))\n",
    "    \n",
    "    if not summary_files:\n",
    "        return None\n",
    "    \n",
    "    summary_file = summary_files[0]\n",
    "    \n",
    "    # Parse summary file\n",
    "    data = {}\n",
    "    with open(summary_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#') or '\\t' not in line:\n",
    "                continue\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                data[parts[0]] = parts[1]\n",
    "    \n",
    "    return PRSResult(\n",
    "        sample=sample,\n",
    "        pgs_id=pgs_id,\n",
    "        method='custom',\n",
    "        build=build,\n",
    "        raw_score=float(data.get('adjusted_score', 0)),\n",
    "        unadjusted_score=float(data.get('unadjusted_score', 0)),\n",
    "        adjusted_score=float(data.get('adjusted_score', 0)),\n",
    "        variants_total=int(data.get('total_variants', 0)),\n",
    "        variants_from_vcf=int(data.get('vcf_found', 0)),\n",
    "        variants_from_ref=int(data.get('ref_lookup_success', 0)),\n",
    "        coverage_pct=float(data.get('adjusted_coverage', 0))\n",
    "    )\n",
    "\n",
    "\n",
    "def load_pgsc_calc_results(results_dir: Path, sample: str, pgs_ids: tuple, build: str) -> list[PRSResult]:\n",
    "    \"\"\"Load results from pgsc_calc output.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Look for aggregated scores file\n",
    "    agg_file = results_dir / 'score' / 'aggregated_scores.txt.gz'\n",
    "    if not agg_file.exists():\n",
    "        agg_file = results_dir / 'aggregated_scores.txt.gz'\n",
    "    \n",
    "    if not agg_file.exists():\n",
    "        print(f\"  Warning: aggregated_scores.txt.gz not found in {results_dir}\")\n",
    "        return results\n",
    "    \n",
    "    # Load aggregated scores\n",
    "    with gzip.open(agg_file, 'rt') as f:\n",
    "        df = pd.read_csv(f, sep='\\t')\n",
    "    \n",
    "    # Look for ancestry/normalized scores\n",
    "    norm_file = results_dir / 'score' / 'pgs.txt.gz'\n",
    "    if not norm_file.exists():\n",
    "        norm_file = results_dir / 'pgs.txt.gz'\n",
    "    \n",
    "    norm_df = None\n",
    "    if norm_file.exists():\n",
    "        with gzip.open(norm_file, 'rt') as f:\n",
    "            norm_df = pd.read_csv(f, sep='\\t')\n",
    "    \n",
    "    # Extract results for each PGS\n",
    "    for pgs_id in pgs_ids:\n",
    "        # Find raw score column\n",
    "        sum_col = f\"{pgs_id}_hmPOS_{build}_SUM\"\n",
    "        if sum_col not in df.columns:\n",
    "            # Try alternative column naming\n",
    "            sum_cols = [c for c in df.columns if pgs_id in c and 'SUM' in c]\n",
    "            if sum_cols:\n",
    "                sum_col = sum_cols[0]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        raw_score = df[sum_col].iloc[0]\n",
    "        \n",
    "        # Get normalized scores if available\n",
    "        z_score = None\n",
    "        percentile = None\n",
    "        ancestry_pop = None\n",
    "        \n",
    "        if norm_df is not None:\n",
    "            z_col = f\"{pgs_id}_Z\"\n",
    "            pct_col = f\"{pgs_id}_percentile\"\n",
    "            \n",
    "            if z_col in norm_df.columns:\n",
    "                z_score = norm_df[z_col].iloc[0]\n",
    "            if pct_col in norm_df.columns:\n",
    "                percentile = norm_df[pct_col].iloc[0]\n",
    "            if 'MostSimilarPop' in norm_df.columns:\n",
    "                ancestry_pop = norm_df['MostSimilarPop'].iloc[0]\n",
    "        \n",
    "        results.append(PRSResult(\n",
    "            sample=sample,\n",
    "            pgs_id=pgs_id,\n",
    "            method='pgsc_calc',\n",
    "            build=build,\n",
    "            raw_score=raw_score,\n",
    "            z_score=z_score,\n",
    "            percentile=percentile,\n",
    "            ancestry_population=ancestry_pop\n",
    "        ))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Result loading functions defined.\")\n",
    "print(\"Run the calculation commands above, then continue with Phase 3.2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Aggregate and Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:36.971203Z",
     "iopub.status.busy": "2026-02-08T22:34:36.970998Z",
     "iopub.status.idle": "2026-02-08T22:34:37.001084Z",
     "shell.execute_reply": "2026-02-08T22:34:37.000476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: aggregated_scores.txt.gz not found in results/methodology_comparison/pgsc_calc/trent\n",
      "Loaded 5 results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>pgs_id</th>\n",
       "      <th>method</th>\n",
       "      <th>build</th>\n",
       "      <th>raw_score</th>\n",
       "      <th>unadjusted_score</th>\n",
       "      <th>adjusted_score</th>\n",
       "      <th>z_score</th>\n",
       "      <th>percentile</th>\n",
       "      <th>ancestry_population</th>\n",
       "      <th>variants_total</th>\n",
       "      <th>variants_matched</th>\n",
       "      <th>variants_from_vcf</th>\n",
       "      <th>variants_from_ref</th>\n",
       "      <th>coverage_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS002308</td>\n",
       "      <td>custom</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>0.392260</td>\n",
       "      <td>0.437142</td>\n",
       "      <td>0.392260</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1259743</td>\n",
       "      <td>None</td>\n",
       "      <td>609023</td>\n",
       "      <td>650720</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004034</td>\n",
       "      <td>custom</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>1.622525</td>\n",
       "      <td>1.677841</td>\n",
       "      <td>1.622525</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1046908</td>\n",
       "      <td>None</td>\n",
       "      <td>556005</td>\n",
       "      <td>490903</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS000027</td>\n",
       "      <td>custom</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>38.640246</td>\n",
       "      <td>17.717730</td>\n",
       "      <td>38.640246</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2100168</td>\n",
       "      <td>None</td>\n",
       "      <td>1083426</td>\n",
       "      <td>1016742</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004237</td>\n",
       "      <td>custom</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>-0.270452</td>\n",
       "      <td>-0.259845</td>\n",
       "      <td>-0.270452</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1146499</td>\n",
       "      <td>None</td>\n",
       "      <td>601193</td>\n",
       "      <td>545306</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004696</td>\n",
       "      <td>custom</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>-0.988260</td>\n",
       "      <td>-0.184619</td>\n",
       "      <td>-0.988260</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1289968</td>\n",
       "      <td>None</td>\n",
       "      <td>612790</td>\n",
       "      <td>677178</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample     pgs_id  method   build  raw_score  unadjusted_score  \\\n",
       "0  Trent  PGS002308  custom  GRCh38   0.392260          0.437142   \n",
       "1  Trent  PGS004034  custom  GRCh38   1.622525          1.677841   \n",
       "2  Trent  PGS000027  custom  GRCh38  38.640246         17.717730   \n",
       "3  Trent  PGS004237  custom  GRCh38  -0.270452         -0.259845   \n",
       "4  Trent  PGS004696  custom  GRCh38  -0.988260         -0.184619   \n",
       "\n",
       "   adjusted_score z_score percentile ancestry_population  variants_total  \\\n",
       "0        0.392260    None       None                None         1259743   \n",
       "1        1.622525    None       None                None         1046908   \n",
       "2       38.640246    None       None                None         2100168   \n",
       "3       -0.270452    None       None                None         1146499   \n",
       "4       -0.988260    None       None                None         1289968   \n",
       "\n",
       "  variants_matched  variants_from_vcf  variants_from_ref  coverage_pct  \n",
       "0             None             609023             650720         100.0  \n",
       "1             None             556005             490903         100.0  \n",
       "2             None            1083426            1016742         100.0  \n",
       "3             None             601193             545306         100.0  \n",
       "4             None             612790             677178         100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_all_results(config: ExperimentConfig) -> pd.DataFrame:\n",
    "    \"\"\"Load all results from both methods and samples.\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Load custom script results\n",
    "    for sample, build in [('Trent', 'GRCh38'), ('Rowen', 'GRCh37')]:\n",
    "        custom_dir = config.results_dir / 'custom' / sample.lower()\n",
    "        if custom_dir.exists():\n",
    "            for pgs_id in config.pgs_ids:\n",
    "                result = load_custom_script_results(custom_dir, sample, pgs_id, build)\n",
    "                if result:\n",
    "                    all_results.append(result)\n",
    "    \n",
    "    # Load pgsc_calc results\n",
    "    for sample, build in [('Trent', 'GRCh38'), ('Rowen', 'GRCh37')]:\n",
    "        pgsc_dir = config.results_dir / 'pgsc_calc' / sample.lower()\n",
    "        if pgsc_dir.exists():\n",
    "            results = load_pgsc_calc_results(pgsc_dir, sample, config.pgs_ids, build)\n",
    "            all_results.extend(results)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if not all_results:\n",
    "        print(\"No results found. Run the calculation commands first.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = pd.DataFrame([r.__dict__ for r in all_results])\n",
    "    return df\n",
    "\n",
    "# Attempt to load results (will be empty until calculations are run)\n",
    "results_df = load_all_results(config)\n",
    "if not results_df.empty:\n",
    "    print(f\"Loaded {len(results_df)} results\")\n",
    "    display(results_df.head(10))\n",
    "else:\n",
    "    print(\"No results found yet. Run the calculation commands from Phase 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Calculate Bias Metrics\n",
    "\n",
    "Key metric: **Homozygous Reference Bias** = (Custom Adjusted - Custom Unadjusted) / Custom Unadjusted * 100%\n",
    "\n",
    "This quantifies how much pgsc_calc (which behaves like \"unadjusted\") underestimates scores for WGS data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.005175Z",
     "iopub.status.busy": "2026-02-08T22:34:37.004937Z",
     "iopub.status.idle": "2026-02-08T22:34:37.021527Z",
     "shell.execute_reply": "2026-02-08T22:34:37.020769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pgsc_calc results available for comparison. Proceeding with custom-only bias analysis.\n"
     ]
    }
   ],
   "source": [
    "def calculate_bias_metrics(results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculate bias metrics comparing methods.\"\"\"\n",
    "    if results_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Pivot to get methods as columns\n",
    "    comparison_data = []\n",
    "    \n",
    "    for sample in results_df['sample'].unique():\n",
    "        for pgs_id in results_df['pgs_id'].unique():\n",
    "            sample_pgs_df = results_df[(results_df['sample'] == sample) & (results_df['pgs_id'] == pgs_id)]\n",
    "            \n",
    "            custom_row = sample_pgs_df[sample_pgs_df['method'] == 'custom']\n",
    "            pgsc_row = sample_pgs_df[sample_pgs_df['method'] == 'pgsc_calc']\n",
    "            \n",
    "            if custom_row.empty or pgsc_row.empty:\n",
    "                continue\n",
    "            \n",
    "            custom = custom_row.iloc[0]\n",
    "            pgsc = pgsc_row.iloc[0]\n",
    "            \n",
    "            # Calculate bias\n",
    "            unadj = custom['unadjusted_score']\n",
    "            adj = custom['adjusted_score']\n",
    "            \n",
    "            if unadj and unadj != 0:\n",
    "                homref_bias_pct = ((adj - unadj) / abs(unadj)) * 100\n",
    "            else:\n",
    "                homref_bias_pct = None\n",
    "            \n",
    "            # Compare pgsc_calc raw to custom scores\n",
    "            pgsc_vs_unadj_diff = None\n",
    "            if pgsc['raw_score'] and unadj:\n",
    "                pgsc_vs_unadj_diff = pgsc['raw_score'] - unadj\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'sample': sample,\n",
    "                'pgs_id': pgs_id,\n",
    "                'build': custom['build'],\n",
    "                'custom_adjusted': adj,\n",
    "                'custom_unadjusted': unadj,\n",
    "                'pgsc_calc_raw': pgsc['raw_score'],\n",
    "                'pgsc_calc_z': pgsc['z_score'],\n",
    "                'pgsc_calc_percentile': pgsc['percentile'],\n",
    "                'homref_bias_pct': homref_bias_pct,\n",
    "                'pgsc_vs_unadj_diff': pgsc_vs_unadj_diff,\n",
    "                'variants_from_ref': custom.get('variants_from_ref'),\n",
    "                'coverage_pct': custom.get('coverage_pct')\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data)\n",
    "\n",
    "# Original function returns empty because pgsc_calc results aren't loading\n",
    "# Let's calculate bias directly from custom results only\n",
    "if not results_df.empty:\n",
    "    bias_df = calculate_bias_metrics(results_df)\n",
    "    if not bias_df.empty:\n",
    "        display(bias_df)\n",
    "    else:\n",
    "        print(\"No pgsc_calc results available for comparison. Proceeding with custom-only bias analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Direct Bias Analysis from Custom Script Results\n",
    "\n",
    "Since the pgsc_calc results use a different file format (long format with `PGS` and `SUM` columns), we calculate the homozygous reference bias directly from the custom script's adjusted vs unadjusted scores.\n",
    "\n",
    "The custom script's \"unadjusted\" score is equivalent to what pgsc_calc produces - it only considers variants found in the VCF and misses homozygous reference sites where the effect allele matches the reference genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.023688Z",
     "iopub.status.busy": "2026-02-08T22:34:37.023555Z",
     "iopub.status.idle": "2026-02-08T22:34:37.076898Z",
     "shell.execute_reply": "2026-02-08T22:34:37.075215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HOMOZYGOUS REFERENCE BIAS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Bias = (Adjusted - Unadjusted) / |Unadjusted| Ã— 100%\n",
      "Positive bias: pgsc_calc UNDERESTIMATES risk (effect alleles match reference)\n",
      "Negative bias: pgsc_calc OVERESTIMATES risk (effect alleles differ from reference)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>PGS_ID</th>\n",
       "      <th>Trait</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Unadjusted</th>\n",
       "      <th>Bias_%</th>\n",
       "      <th>Variants_from_Ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004696</td>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-435.30</td>\n",
       "      <td>677178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS000027</td>\n",
       "      <td>BMI</td>\n",
       "      <td>38.64</td>\n",
       "      <td>17.72</td>\n",
       "      <td>118.09</td>\n",
       "      <td>1016742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS002308</td>\n",
       "      <td>Type 2 Diabetes</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-10.27</td>\n",
       "      <td>650720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004237</td>\n",
       "      <td>CAD</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>545306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004034</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>490903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample     PGS_ID                Trait  Adjusted  Unadjusted  Bias_%  \\\n",
       "4  Trent  PGS004696                  CHD     -0.99       -0.18 -435.30   \n",
       "2  Trent  PGS000027                  BMI     38.64       17.72  118.09   \n",
       "0  Trent  PGS002308      Type 2 Diabetes      0.39        0.44  -10.27   \n",
       "3  Trent  PGS004237                  CAD     -0.27       -0.26   -4.08   \n",
       "1  Trent  PGS004034  Alzheimer's Disease      1.62        1.68   -3.30   \n",
       "\n",
       "   Variants_from_Ref  \n",
       "4             677178  \n",
       "2            1016742  \n",
       "0             650720  \n",
       "3             545306  \n",
       "1             490903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate homozygous reference bias directly from custom results\n",
    "# This doesn't require pgsc_calc results - the custom script provides both adjusted and unadjusted scores\n",
    "\n",
    "# PGS ID to trait name mapping\n",
    "pgs_traits = {\n",
    "    'PGS002308': 'Type 2 Diabetes',\n",
    "    'PGS004034': 'Alzheimer\\'s Disease', \n",
    "    'PGS000027': 'BMI',\n",
    "    'PGS004237': 'CAD',\n",
    "    'PGS004696': 'CHD'\n",
    "}\n",
    "\n",
    "# Filter to custom results only\n",
    "custom_results = results_df[results_df['method'] == 'custom'].copy()\n",
    "\n",
    "# Calculate bias percentage: (adjusted - unadjusted) / |unadjusted| * 100\n",
    "custom_results['homref_bias_pct'] = (\n",
    "    (custom_results['adjusted_score'] - custom_results['unadjusted_score']) \n",
    "    / custom_results['unadjusted_score'].abs() * 100\n",
    ")\n",
    "\n",
    "# Add trait names\n",
    "custom_results['trait'] = custom_results['pgs_id'].map(pgs_traits)\n",
    "\n",
    "# Create summary bias table\n",
    "bias_table = custom_results[['sample', 'pgs_id', 'trait', 'adjusted_score', 'unadjusted_score', 'homref_bias_pct', 'variants_from_ref']].copy()\n",
    "bias_table.columns = ['Sample', 'PGS_ID', 'Trait', 'Adjusted', 'Unadjusted', 'Bias_%', 'Variants_from_Ref']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HOMOZYGOUS REFERENCE BIAS ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nBias = (Adjusted - Unadjusted) / |Unadjusted| Ã— 100%\")\n",
    "print(\"Positive bias: pgsc_calc UNDERESTIMATES risk (effect alleles match reference)\")\n",
    "print(\"Negative bias: pgsc_calc OVERESTIMATES risk (effect alleles differ from reference)\")\n",
    "print()\n",
    "\n",
    "# Sort by absolute bias magnitude\n",
    "bias_table_sorted = bias_table.sort_values('Bias_%', key=abs, ascending=False)\n",
    "display(bias_table_sorted.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.089699Z",
     "iopub.status.busy": "2026-02-08T22:34:37.085949Z",
     "iopub.status.idle": "2026-02-08T22:34:37.292412Z",
     "shell.execute_reply": "2026-02-08T22:34:37.291468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pgsc_calc results (long format)...\n",
      "\n",
      "Trent:\n",
      "  Loaded raw scores: 4 rows\n",
      "  Loaded normalized scores: 6 rows for Trent\n",
      "\n",
      "Loaded 4 pgsc_calc results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>pgs_id</th>\n",
       "      <th>method</th>\n",
       "      <th>build</th>\n",
       "      <th>raw_score</th>\n",
       "      <th>z_score</th>\n",
       "      <th>percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS002308</td>\n",
       "      <td>pgsc_calc</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>0.436293</td>\n",
       "      <td>2.761803</td>\n",
       "      <td>99.700150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004034</td>\n",
       "      <td>pgsc_calc</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>1.677837</td>\n",
       "      <td>0.490730</td>\n",
       "      <td>64.017991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS000027</td>\n",
       "      <td>pgsc_calc</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>17.716960</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>51.574213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004237</td>\n",
       "      <td>pgsc_calc</td>\n",
       "      <td>GRCh38</td>\n",
       "      <td>-0.258624</td>\n",
       "      <td>-1.468964</td>\n",
       "      <td>7.196402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample     pgs_id     method   build  raw_score   z_score  percentile\n",
       "0  Trent  PGS002308  pgsc_calc  GRCh38   0.436293  2.761803   99.700150\n",
       "1  Trent  PGS004034  pgsc_calc  GRCh38   1.677837  0.490730   64.017991\n",
       "2  Trent  PGS000027  pgsc_calc  GRCh38  17.716960  0.058853   51.574213\n",
       "3  Trent  PGS004237  pgsc_calc  GRCh38  -0.258624 -1.468964    7.196402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pgsc_calc ancestry-normalized results from actual file format\n",
    "# The pgsc_calc output uses long format: one row per PGS per sample\n",
    "\n",
    "def load_pgsc_calc_long_format(results_dir: Path, sample: str, pgs_ids: tuple, build: str) -> pd.DataFrame:\n",
    "    \"\"\"Load pgsc_calc results from long-format output files.\"\"\"\n",
    "    \n",
    "    # Look for raw_scores.txt.gz (unadjusted scores)\n",
    "    raw_file = results_dir / 'raw_scores.txt.gz'\n",
    "    \n",
    "    # Look for trent_pgs.txt.gz or {sample}_pgs.txt.gz (ancestry-normalized)\n",
    "    norm_file = results_dir / f'{sample.lower()}_pgs.txt.gz'\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Load raw scores\n",
    "    raw_df = None\n",
    "    if raw_file.exists():\n",
    "        raw_df = pd.read_csv(raw_file, sep='\\t', compression='gzip')\n",
    "        print(f\"  Loaded raw scores: {len(raw_df)} rows\")\n",
    "    else:\n",
    "        print(f\"  Warning: raw_scores.txt.gz not found in {results_dir}\")\n",
    "    \n",
    "    # Load ancestry-normalized scores\n",
    "    norm_df = None\n",
    "    if norm_file.exists():\n",
    "        norm_df = pd.read_csv(norm_file, sep='\\t', compression='gzip')\n",
    "        # Filter to sample's rows (exclude 'reference' sampleset)\n",
    "        norm_df = norm_df[norm_df['sampleset'] == sample.lower()].copy()\n",
    "        print(f\"  Loaded normalized scores: {len(norm_df)} rows for {sample}\")\n",
    "    else:\n",
    "        print(f\"  Warning: {sample.lower()}_pgs.txt.gz not found in {results_dir}\")\n",
    "    \n",
    "    # Combine into results\n",
    "    for pgs_id in pgs_ids:\n",
    "        pgs_pattern = f\"{pgs_id}_hmPOS_{build}\"\n",
    "        \n",
    "        raw_score = None\n",
    "        z_score = None\n",
    "        percentile = None\n",
    "        \n",
    "        if raw_df is not None:\n",
    "            pgs_row = raw_df[raw_df['PGS'].str.contains(pgs_id, na=False)]\n",
    "            if not pgs_row.empty:\n",
    "                raw_score = pgs_row.iloc[0]['SUM']\n",
    "        \n",
    "        if norm_df is not None:\n",
    "            pgs_row = norm_df[norm_df['PGS'].str.contains(pgs_id, na=False)]\n",
    "            if not pgs_row.empty:\n",
    "                z_score = pgs_row.iloc[0].get('Z_MostSimilarPop', None)\n",
    "                percentile = pgs_row.iloc[0].get('percentile_MostSimilarPop', None)\n",
    "        \n",
    "        if raw_score is not None or z_score is not None:\n",
    "            results.append({\n",
    "                'sample': sample,\n",
    "                'pgs_id': pgs_id,\n",
    "                'method': 'pgsc_calc',\n",
    "                'build': build,\n",
    "                'raw_score': raw_score,\n",
    "                'z_score': z_score,\n",
    "                'percentile': percentile\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Load pgsc_calc results for Trent (Rowen doesn't have pgsc_calc results)\n",
    "print(\"Loading pgsc_calc results (long format)...\")\n",
    "print()\n",
    "\n",
    "pgsc_results = []\n",
    "\n",
    "# Trent - has pgsc_calc ancestry results\n",
    "trent_pgsc_dir = config.results_dir / 'pgsc_calc' / 'trent'\n",
    "if trent_pgsc_dir.exists():\n",
    "    print(\"Trent:\")\n",
    "    trent_pgsc = load_pgsc_calc_long_format(trent_pgsc_dir, 'Trent', config.pgs_ids, 'GRCh38')\n",
    "    if not trent_pgsc.empty:\n",
    "        pgsc_results.append(trent_pgsc)\n",
    "\n",
    "# Combine\n",
    "if pgsc_results:\n",
    "    pgsc_df = pd.concat(pgsc_results, ignore_index=True)\n",
    "    print(f\"\\nLoaded {len(pgsc_df)} pgsc_calc results:\")\n",
    "    display(pgsc_df)\n",
    "else:\n",
    "    pgsc_df = pd.DataFrame()\n",
    "    print(\"No pgsc_calc results loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Comprehensive Comparison: Custom vs pgsc_calc\n",
    "\n",
    "Merge custom script results with pgsc_calc results to create a complete comparison table. This validates:\n",
    "1. **Score equivalence**: pgsc_calc raw scores â‰ˆ custom unadjusted scores (both ignore hom-ref sites)\n",
    "2. **Bias magnitude**: How much the adjusted score differs from unadjusted\n",
    "3. **Ancestry percentiles**: Where the sample falls in the European population distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.294611Z",
     "iopub.status.busy": "2026-02-08T22:34:37.294423Z",
     "iopub.status.idle": "2026-02-08T22:34:37.332451Z",
     "shell.execute_reply": "2026-02-08T22:34:37.331395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "COMPREHENSIVE METHODOLOGY COMPARISON\n",
      "====================================================================================================\n",
      "\n",
      "Key columns:\n",
      "  - adjusted_score: Custom script score WITH reference genome lookup (correct for WGS)\n",
      "  - unadjusted_score: Custom script score WITHOUT reference lookup (equivalent to pgsc_calc)\n",
      "  - pgsc_raw_score: pgsc_calc raw score (should match unadjusted_score)\n",
      "  - homref_bias_pct: Percentage difference showing systematic bias in pgsc_calc\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>pgs_id</th>\n",
       "      <th>trait</th>\n",
       "      <th>adjusted_score</th>\n",
       "      <th>unadjusted_score</th>\n",
       "      <th>homref_bias_pct</th>\n",
       "      <th>variants_from_vcf</th>\n",
       "      <th>variants_from_ref</th>\n",
       "      <th>pgsc_raw_score</th>\n",
       "      <th>pgsc_z_score</th>\n",
       "      <th>pgsc_percentile</th>\n",
       "      <th>raw_score_diff</th>\n",
       "      <th>raw_score_diff_pct</th>\n",
       "      <th>interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS002308</td>\n",
       "      <td>Type 2 Diabetes</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.437</td>\n",
       "      <td>-10.267</td>\n",
       "      <td>609023</td>\n",
       "      <td>650720</td>\n",
       "      <td>0.436</td>\n",
       "      <td>2.762</td>\n",
       "      <td>99.700</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>âš ï¸ Overestimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004034</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>1.623</td>\n",
       "      <td>1.678</td>\n",
       "      <td>-3.297</td>\n",
       "      <td>556005</td>\n",
       "      <td>490903</td>\n",
       "      <td>1.678</td>\n",
       "      <td>0.491</td>\n",
       "      <td>64.018</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>âœ“ Minimal bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS000027</td>\n",
       "      <td>BMI</td>\n",
       "      <td>38.640</td>\n",
       "      <td>17.718</td>\n",
       "      <td>118.088</td>\n",
       "      <td>1083426</td>\n",
       "      <td>1016742</td>\n",
       "      <td>17.717</td>\n",
       "      <td>0.059</td>\n",
       "      <td>51.574</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>âš ï¸ SEVERE UNDERESTIMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004237</td>\n",
       "      <td>CAD</td>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-4.082</td>\n",
       "      <td>601193</td>\n",
       "      <td>545306</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-1.469</td>\n",
       "      <td>7.196</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.470</td>\n",
       "      <td>âœ“ Minimal bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004696</td>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.988</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>-435.297</td>\n",
       "      <td>612790</td>\n",
       "      <td>677178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>âš ï¸ SEVERE OVERESTIMATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample     pgs_id                trait  adjusted_score  unadjusted_score  \\\n",
       "0  Trent  PGS002308      Type 2 Diabetes           0.392             0.437   \n",
       "1  Trent  PGS004034  Alzheimer's Disease           1.623             1.678   \n",
       "2  Trent  PGS000027                  BMI          38.640            17.718   \n",
       "3  Trent  PGS004237                  CAD          -0.270            -0.260   \n",
       "4  Trent  PGS004696                  CHD          -0.988            -0.185   \n",
       "\n",
       "   homref_bias_pct  variants_from_vcf  variants_from_ref  pgsc_raw_score  \\\n",
       "0          -10.267             609023             650720           0.436   \n",
       "1           -3.297             556005             490903           1.678   \n",
       "2          118.088            1083426            1016742          17.717   \n",
       "3           -4.082             601193             545306          -0.259   \n",
       "4         -435.297             612790             677178             NaN   \n",
       "\n",
       "   pgsc_z_score  pgsc_percentile  raw_score_diff  raw_score_diff_pct  \\\n",
       "0         2.762           99.700          -0.001              -0.194   \n",
       "1         0.491           64.018          -0.000              -0.000   \n",
       "2         0.059           51.574          -0.001              -0.004   \n",
       "3        -1.469            7.196           0.001               0.470   \n",
       "4           NaN              NaN             NaN                 NaN   \n",
       "\n",
       "            interpretation  \n",
       "0          âš ï¸ Overestimate  \n",
       "1           âœ“ Minimal bias  \n",
       "2  âš ï¸ SEVERE UNDERESTIMATE  \n",
       "3           âœ“ Minimal bias  \n",
       "4   âš ï¸ SEVERE OVERESTIMATE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create comprehensive comparison table\n",
    "# Merge custom script results with pgsc_calc results\n",
    "\n",
    "# Prepare custom results for merge\n",
    "custom_for_merge = custom_results[['sample', 'pgs_id', 'trait', 'adjusted_score', 'unadjusted_score', \n",
    "                                    'homref_bias_pct', 'variants_from_vcf', 'variants_from_ref']].copy()\n",
    "\n",
    "# Prepare pgsc_calc results for merge\n",
    "if not pgsc_df.empty:\n",
    "    pgsc_for_merge = pgsc_df[['sample', 'pgs_id', 'raw_score', 'z_score', 'percentile']].copy()\n",
    "    pgsc_for_merge.columns = ['sample', 'pgs_id', 'pgsc_raw_score', 'pgsc_z_score', 'pgsc_percentile']\n",
    "    \n",
    "    # Merge\n",
    "    comparison_df = custom_for_merge.merge(pgsc_for_merge, on=['sample', 'pgs_id'], how='left')\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    comparison_df['raw_score_diff'] = comparison_df['pgsc_raw_score'] - comparison_df['unadjusted_score']\n",
    "    comparison_df['raw_score_diff_pct'] = (comparison_df['raw_score_diff'] / comparison_df['unadjusted_score'].abs() * 100)\n",
    "else:\n",
    "    comparison_df = custom_for_merge.copy()\n",
    "    comparison_df['pgsc_raw_score'] = None\n",
    "    comparison_df['pgsc_z_score'] = None\n",
    "    comparison_df['pgsc_percentile'] = None\n",
    "    comparison_df['raw_score_diff'] = None\n",
    "    comparison_df['raw_score_diff_pct'] = None\n",
    "\n",
    "# Add interpretation column\n",
    "def interpret_bias(bias_pct):\n",
    "    if pd.isna(bias_pct):\n",
    "        return \"N/A\"\n",
    "    if bias_pct > 50:\n",
    "        return \"âš ï¸ SEVERE UNDERESTIMATE\"\n",
    "    elif bias_pct > 10:\n",
    "        return \"âš ï¸ Underestimate\"\n",
    "    elif bias_pct < -50:\n",
    "        return \"âš ï¸ SEVERE OVERESTIMATE\"\n",
    "    elif bias_pct < -10:\n",
    "        return \"âš ï¸ Overestimate\"\n",
    "    else:\n",
    "        return \"âœ“ Minimal bias\"\n",
    "\n",
    "comparison_df['interpretation'] = comparison_df['homref_bias_pct'].apply(interpret_bias)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"COMPREHENSIVE METHODOLOGY COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "print()\n",
    "print(\"Key columns:\")\n",
    "print(\"  - adjusted_score: Custom script score WITH reference genome lookup (correct for WGS)\")\n",
    "print(\"  - unadjusted_score: Custom script score WITHOUT reference lookup (equivalent to pgsc_calc)\")\n",
    "print(\"  - pgsc_raw_score: pgsc_calc raw score (should match unadjusted_score)\")\n",
    "print(\"  - homref_bias_pct: Percentage difference showing systematic bias in pgsc_calc\")\n",
    "print()\n",
    "\n",
    "display(comparison_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.334908Z",
     "iopub.status.busy": "2026-02-08T22:34:37.334590Z",
     "iopub.status.idle": "2026-02-08T22:34:37.359598Z",
     "shell.execute_reply": "2026-02-08T22:34:37.358652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Exported comparison data to: results/methodology_comparison/comprehensive_bias_analysis.csv\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE FOR TECHNICAL REPORT\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>PGS ID</th>\n",
       "      <th>Trait</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Unadjusted</th>\n",
       "      <th>Bias %</th>\n",
       "      <th>Interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS002308</td>\n",
       "      <td>Type 2 Diabetes</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-10.27</td>\n",
       "      <td>âš ï¸ Overestimate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004034</td>\n",
       "      <td>Alzheimer's Disease</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.68</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>âœ“ Minimal bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS000027</td>\n",
       "      <td>BMI</td>\n",
       "      <td>38.64</td>\n",
       "      <td>17.72</td>\n",
       "      <td>118.09</td>\n",
       "      <td>âš ï¸ SEVERE UNDERESTIMATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004237</td>\n",
       "      <td>CAD</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-4.08</td>\n",
       "      <td>âœ“ Minimal bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent</td>\n",
       "      <td>PGS004696</td>\n",
       "      <td>CHD</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-435.30</td>\n",
       "      <td>âš ï¸ SEVERE OVERESTIMATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sample     PGS ID                Trait  Adjusted  Unadjusted  Bias %  \\\n",
       "0  Trent  PGS002308      Type 2 Diabetes      0.39        0.44  -10.27   \n",
       "1  Trent  PGS004034  Alzheimer's Disease      1.62        1.68   -3.30   \n",
       "2  Trent  PGS000027                  BMI     38.64       17.72  118.09   \n",
       "3  Trent  PGS004237                  CAD     -0.27       -0.26   -4.08   \n",
       "4  Trent  PGS004696                  CHD     -0.99       -0.18 -435.30   \n",
       "\n",
       "            Interpretation  \n",
       "0          âš ï¸ Overestimate  \n",
       "1           âœ“ Minimal bias  \n",
       "2  âš ï¸ SEVERE UNDERESTIMATE  \n",
       "3           âœ“ Minimal bias  \n",
       "4   âš ï¸ SEVERE OVERESTIMATE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Exported summary table to: results/methodology_comparison/bias_summary_for_report.csv\n"
     ]
    }
   ],
   "source": [
    "# Export comprehensive results to CSV\n",
    "output_csv = config.results_dir / 'comprehensive_bias_analysis.csv'\n",
    "comparison_df.to_csv(output_csv, index=False)\n",
    "print(f\"âœ… Exported comparison data to: {output_csv}\")\n",
    "\n",
    "# Also create a summary table for the technical report\n",
    "report_table = comparison_df[['sample', 'pgs_id', 'trait', 'adjusted_score', 'unadjusted_score', \n",
    "                               'homref_bias_pct', 'interpretation']].copy()\n",
    "report_table.columns = ['Sample', 'PGS ID', 'Trait', 'Adjusted', 'Unadjusted', 'Bias %', 'Interpretation']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY TABLE FOR TECHNICAL REPORT\")\n",
    "print(\"=\" * 80)\n",
    "display(report_table.round(2))\n",
    "\n",
    "# Export summary table \n",
    "summary_csv = config.results_dir / 'bias_summary_for_report.csv'\n",
    "report_table.to_csv(summary_csv, index=False)\n",
    "print(f\"\\nâœ… Exported summary table to: {summary_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.361512Z",
     "iopub.status.busy": "2026-02-08T22:34:37.361313Z",
     "iopub.status.idle": "2026-02-08T22:34:37.379264Z",
     "shell.execute_reply": "2026-02-08T22:34:37.378128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KEY FINDINGS: HOMOZYGOUS REFERENCE BIAS IN pgsc_calc\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š AGGREGATE STATISTICS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â€¢ Average absolute bias across all scores: 114.2%\n",
      "â€¢ Maximum underestimation (positive bias): +118.1%\n",
      "â€¢ Maximum overestimation (negative bias): -435.3%\n",
      "\n",
      "ðŸ” MOST AFFECTED SCORES\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â€¢ PGS000027 (BMI): +118.1% bias - pgsc_calc SEVERELY UNDERESTIMATES\n",
      "  â†’ Effect alleles frequently match reference genome\n",
      "  â†’ Missing ~1M homozygous reference sites per sample\n",
      "\n",
      "â€¢ PGS004696 (CHD): -435.3% bias - pgsc_calc SEVERELY OVERESTIMATES  \n",
      "  â†’ Effect alleles frequently differ from reference genome\n",
      "  â†’ Reference lookup reveals protective effect was missed\n",
      "\n",
      "âš ï¸ CRITICAL INSIGHT\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "The direction and magnitude of bias depends on how the PGS was constructed:\n",
      "â€¢ Scores where effect alleles tend to be the non-reference allele â†’ UNDERESTIMATE risk\n",
      "â€¢ Scores where effect alleles tend to be the reference allele â†’ OVERESTIMATE risk\n",
      "\n",
      "Ancestry normalization does NOT correct this bias because the reference panel\n",
      "(HGDP+1kGP) was scored using the same biased method!\n",
      "\n",
      "âœ… RECOMMENDATION\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "For WGS data: Use reference genome lookup (custom script) for accurate PRS.\n",
      "The \"adjusted_score\" column contains the corrected values.\n",
      "\n",
      "\n",
      "âœ“ VALIDATION: pgsc_calc raw scores match custom unadjusted (max diff: 0.001221)\n"
     ]
    }
   ],
   "source": [
    "# Key findings summary\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY FINDINGS: HOMOZYGOUS REFERENCE BIAS IN pgsc_calc\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate aggregate statistics\n",
    "avg_bias_abs = comparison_df['homref_bias_pct'].abs().mean()\n",
    "max_underestimate = comparison_df[comparison_df['homref_bias_pct'] > 0]['homref_bias_pct'].max()\n",
    "max_overestimate = comparison_df[comparison_df['homref_bias_pct'] < 0]['homref_bias_pct'].min()\n",
    "\n",
    "# Most affected scores\n",
    "most_biased = comparison_df.loc[comparison_df['homref_bias_pct'].abs().idxmax()]\n",
    "bmi_bias = comparison_df[comparison_df['pgs_id'] == 'PGS000027']['homref_bias_pct'].mean()\n",
    "chd_bias = comparison_df[comparison_df['pgs_id'] == 'PGS004696']['homref_bias_pct'].mean()\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š AGGREGATE STATISTICS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Average absolute bias across all scores: {avg_bias_abs:.1f}%\n",
    "â€¢ Maximum underestimation (positive bias): +{max_underestimate:.1f}%\n",
    "â€¢ Maximum overestimation (negative bias): {max_overestimate:.1f}%\n",
    "\n",
    "ðŸ” MOST AFFECTED SCORES\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ PGS000027 (BMI): {bmi_bias:+.1f}% bias - pgsc_calc SEVERELY UNDERESTIMATES\n",
    "  â†’ Effect alleles frequently match reference genome\n",
    "  â†’ Missing ~1M homozygous reference sites per sample\n",
    "  \n",
    "â€¢ PGS004696 (CHD): {chd_bias:+.1f}% bias - pgsc_calc SEVERELY OVERESTIMATES  \n",
    "  â†’ Effect alleles frequently differ from reference genome\n",
    "  â†’ Reference lookup reveals protective effect was missed\n",
    "\n",
    "âš ï¸ CRITICAL INSIGHT\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "The direction and magnitude of bias depends on how the PGS was constructed:\n",
    "â€¢ Scores where effect alleles tend to be the non-reference allele â†’ UNDERESTIMATE risk\n",
    "â€¢ Scores where effect alleles tend to be the reference allele â†’ OVERESTIMATE risk\n",
    "\n",
    "Ancestry normalization does NOT correct this bias because the reference panel\n",
    "(HGDP+1kGP) was scored using the same biased method!\n",
    "\n",
    "âœ… RECOMMENDATION\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "For WGS data: Use reference genome lookup (custom script) for accurate PRS.\n",
    "The \"adjusted_score\" column contains the corrected values.\n",
    "\"\"\")\n",
    "\n",
    "# Validation check: pgsc_calc raw should match custom unadjusted\n",
    "if 'pgsc_raw_score' in comparison_df.columns and comparison_df['pgsc_raw_score'].notna().any():\n",
    "    valid_rows = comparison_df[comparison_df['pgsc_raw_score'].notna()]\n",
    "    score_diffs = (valid_rows['pgsc_raw_score'] - valid_rows['unadjusted_score']).abs()\n",
    "    max_diff = score_diffs.max()\n",
    "    print(f\"\\nâœ“ VALIDATION: pgsc_calc raw scores match custom unadjusted (max diff: {max_diff:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Visualization\n",
    "\n",
    "### 4.1 Score Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.382162Z",
     "iopub.status.busy": "2026-02-08T22:34:37.381927Z",
     "iopub.status.idle": "2026-02-08T22:34:37.403830Z",
     "shell.execute_reply": "2026-02-08T22:34:37.402894Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_method_comparison(comparison_df: pd.DataFrame, output_path: Optional[Path] = None):\n",
    "    \"\"\"Create visualization comparing methods.\"\"\"\n",
    "    if comparison_df.empty:\n",
    "        print(\"No comparison data available.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Plot 1: Custom Adjusted vs Unadjusted\n",
    "    ax1 = axes[0, 0]\n",
    "    for sample in comparison_df['sample'].unique():\n",
    "        sample_df = comparison_df[comparison_df['sample'] == sample]\n",
    "        ax1.scatter(sample_df['custom_unadjusted'], sample_df['custom_adjusted'], \n",
    "                   label=sample, s=100, alpha=0.7)\n",
    "    \n",
    "    # Add identity line\n",
    "    lims = [min(ax1.get_xlim()[0], ax1.get_ylim()[0]), \n",
    "            max(ax1.get_xlim()[1], ax1.get_ylim()[1])]\n",
    "    ax1.plot(lims, lims, 'k--', alpha=0.5, label='y=x')\n",
    "    ax1.set_xlabel('Custom Unadjusted (VCF only)')\n",
    "    ax1.set_ylabel('Custom Adjusted (+ ref lookup)')\n",
    "    ax1.set_title('Custom Script: Impact of Reference Lookup')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: pgsc_calc Raw vs Custom Unadjusted\n",
    "    ax2 = axes[0, 1]\n",
    "    for sample in comparison_df['sample'].unique():\n",
    "        sample_df = comparison_df[comparison_df['sample'] == sample]\n",
    "        ax2.scatter(sample_df['custom_unadjusted'], sample_df['pgsc_calc_raw'],\n",
    "                   label=sample, s=100, alpha=0.7)\n",
    "    \n",
    "    lims = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]),\n",
    "            max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
    "    ax2.plot(lims, lims, 'k--', alpha=0.5, label='y=x')\n",
    "    ax2.set_xlabel('Custom Unadjusted')\n",
    "    ax2.set_ylabel('pgsc_calc Raw')\n",
    "    ax2.set_title('Method Comparison: Should Be ~Equal')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Plot 3: Homozygous Reference Bias by PGS\n",
    "    ax3 = axes[1, 0]\n",
    "    bias_pivot = comparison_df.pivot(index='pgs_id', columns='sample', values='homref_bias_pct')\n",
    "    bias_pivot.plot(kind='bar', ax=ax3)\n",
    "    ax3.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "    ax3.set_ylabel('Bias (%)')\n",
    "    ax3.set_title('Homozygous Reference Bias by Score')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 4: Coverage vs Bias\n",
    "    ax4 = axes[1, 1]\n",
    "    scatter = ax4.scatter(comparison_df['variants_from_ref'], \n",
    "                         comparison_df['homref_bias_pct'],\n",
    "                         c=comparison_df['sample'].astype('category').cat.codes,\n",
    "                         s=100, alpha=0.7)\n",
    "    ax4.set_xlabel('Variants from Reference Lookup')\n",
    "    ax4.set_ylabel('Homozygous Reference Bias (%)')\n",
    "    ax4.set_title('More Ref Lookups â†’ More Potential Bias')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_path:\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved figure to {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Run when results are available\n",
    "# plot_method_comparison(bias_df, config.results_dir / 'method_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Ancestry Correction Deep Dive\n",
    "\n",
    "Key question: Does pgsc_calc's ancestry normalization account for the homozygous reference bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.406164Z",
     "iopub.status.busy": "2026-02-08T22:34:37.405968Z",
     "iopub.status.idle": "2026-02-08T22:34:37.428497Z",
     "shell.execute_reply": "2026-02-08T22:34:37.426179Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_ancestry_correction(comparison_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze whether ancestry correction accounts for homref bias.\n",
    "    \n",
    "    Theory:\n",
    "    - If the reference panel (HGDP+1kGP) was scored WITH reference lookup,\n",
    "      then pgsc_calc's normalization should account for the bias.\n",
    "    - If scored WITHOUT reference lookup (likely), the bias persists.\n",
    "    \n",
    "    Test: Compare Z-score implied by custom adjusted score vs pgsc_calc Z-score.\n",
    "    \"\"\"\n",
    "    if comparison_df.empty or 'pgsc_calc_z' not in comparison_df.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    analysis_data = []\n",
    "    \n",
    "    for _, row in comparison_df.iterrows():\n",
    "        if pd.isna(row['pgsc_calc_z']):\n",
    "            continue\n",
    "        \n",
    "        # pgsc_calc Z-score is based on raw (unadjusted-equivalent) score\n",
    "        pgsc_z = row['pgsc_calc_z']\n",
    "        \n",
    "        # If we applied the same normalization to the adjusted score,\n",
    "        # we'd expect a different Z-score\n",
    "        # Approximation: Z_adjusted â‰ˆ Z_raw + (bias_pct / 100) * some_factor\n",
    "        # This is a simplification - actual relationship depends on score distribution\n",
    "        \n",
    "        homref_bias = row['homref_bias_pct'] if row['homref_bias_pct'] else 0\n",
    "        \n",
    "        analysis_data.append({\n",
    "            'sample': row['sample'],\n",
    "            'pgs_id': row['pgs_id'],\n",
    "            'pgsc_calc_z': pgsc_z,\n",
    "            'pgsc_calc_percentile': row['pgsc_calc_percentile'],\n",
    "            'homref_bias_pct': homref_bias,\n",
    "            'interpretation': _interpret_bias(homref_bias, pgsc_z)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(analysis_data)\n",
    "\n",
    "def _interpret_bias(bias_pct: float, z_score: float) -> str:\n",
    "    \"\"\"Provide interpretation of bias significance.\"\"\"\n",
    "    if abs(bias_pct) < 1:\n",
    "        return \"Minimal bias - results reliable\"\n",
    "    elif abs(bias_pct) < 5:\n",
    "        return \"Low bias - minor adjustment may be needed\"\n",
    "    elif abs(bias_pct) < 20:\n",
    "        return \"Moderate bias - interpret with caution\"\n",
    "    else:\n",
    "        return \"HIGH BIAS - pgsc_calc results unreliable for this score\"\n",
    "\n",
    "# Run when results are available\n",
    "# ancestry_analysis = analyze_ancestry_correction(bias_df)\n",
    "# display(ancestry_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T22:34:37.432437Z",
     "iopub.status.busy": "2026-02-08T22:34:37.432057Z",
     "iopub.status.idle": "2026-02-08T22:34:37.451829Z",
     "shell.execute_reply": "2026-02-08T22:34:37.450359Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_summary_report(comparison_df: pd.DataFrame, output_path: Optional[Path] = None) -> str:\n",
    "    \"\"\"Generate a markdown summary report.\"\"\"\n",
    "    if comparison_df.empty:\n",
    "        return \"No results available for summary.\"\n",
    "    \n",
    "    lines = [\n",
    "        \"# PRS Methodology Experiment: Summary Report\",\n",
    "        \"\",\n",
    "        \"## Key Findings\",\n",
    "        \"\",\n",
    "        \"### Homozygous Reference Bias\",\n",
    "        \"\",\n",
    "        \"| Sample | PGS ID | Bias (%) | Interpretation |\",\n",
    "        \"|--------|--------|----------|----------------|\",\n",
    "    ]\n",
    "    \n",
    "    for _, row in comparison_df.iterrows():\n",
    "        bias = row.get('homref_bias_pct', 0)\n",
    "        interp = _interpret_bias(bias, 0)\n",
    "        lines.append(f\"| {row['sample']} | {row['pgs_id']} | {bias:.1f}% | {interp} |\")\n",
    "    \n",
    "    lines.extend([\n",
    "        \"\",\n",
    "        \"### pgsc_calc vs Custom Script Agreement\",\n",
    "        \"\",\n",
    "        \"The pgsc_calc raw scores should closely match the custom script's 'unadjusted' scores,\",\n",
    "        \"as both ignore homozygous reference sites not present in the VCF.\",\n",
    "        \"\",\n",
    "        \"### Ancestry Correction Behavior\",\n",
    "        \"\",\n",
    "        \"**Critical Question**: Does pgsc_calc's ancestry normalization correct for the homref bias?\",\n",
    "        \"\",\n",
    "        \"**Answer**: Most likely **NO**. The HGDP+1kGP reference panel was scored using standard\",\n",
    "        \"PLINK scoring, which also ignores homozygous reference sites. Therefore:\",\n",
    "        \"\",\n",
    "        \"- The bias affects both the sample AND the reference panel equally\",\n",
    "        \"- Z-scores and percentiles remain biased in the same direction\",\n",
    "        \"- For scores where effect alleles are systematically REF-oriented, pgsc_calc will\",\n",
    "        \"  **underestimate** genetic risk for WGS data\",\n",
    "        \"\",\n",
    "        \"## Recommendations\",\n",
    "        \"\",\n",
    "        \"1. **For WGS data**: Use the custom script's adjusted scores for accurate PRS values\",\n",
    "        \"2. **For ancestry normalization**: Apply custom normalization using adjusted scores\",\n",
    "        \"3. **For array data**: pgsc_calc is appropriate (designed for imputed data)\",\n",
    "        \"4. **Score selection**: Prefer scores with balanced effect allele orientation\",\n",
    "    ])\n",
    "    \n",
    "    report = \"\\n\".join(lines)\n",
    "    \n",
    "    if output_path:\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        print(f\"Report saved to {output_path}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Run when results are available\n",
    "# report = generate_summary_report(bias_df, config.results_dir / 'summary_report.md')\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Understanding pgsc_calc Ancestry Correction\n",
    "\n",
    "Based on [Lambert et al. 2024](https://doi.org/10.1101/2024.05.29.24307783), pgsc_calc implements these normalization methods:\n",
    "\n",
    "### Population-Based Normalization\n",
    "1. Project sample into PCA space using HGDP+1kGP reference\n",
    "2. Identify most similar population (EUR, AFR, EAS, etc.)\n",
    "3. Calculate Z-score: `(sample_PGS - pop_mean) / pop_sd`\n",
    "4. Convert to percentile\n",
    "\n",
    "### Continuous (Regression-Based) Normalization\n",
    "1. Fit regression: `PGS ~ PC1 + PC2 + ... + PCn` on reference panel\n",
    "2. Predict expected PGS for sample based on PCA loadings\n",
    "3. Calculate residual as ancestry-adjusted PGS\n",
    "\n",
    "### Why Neither Method Fixes the Homref Bias\n",
    "\n",
    "Both methods compare the sample's score to reference panel scores. If both were calculated\n",
    "using the same method (VCF-only, no reference lookup), the comparison is **internally consistent**\n",
    "but **externally biased**.\n",
    "\n",
    "The Z-score tells you where you fall relative to others scored the same way - not your true\n",
    "genetic predisposition.\n",
    "\n",
    "### Implications for Clinical Use\n",
    "\n",
    "For clinical risk stratification:\n",
    "- Raw Z-scores from pgsc_calc may underestimate risk for WGS samples\n",
    "- The bias magnitude depends on the score's effect allele orientation\n",
    "- Scores using PRS-CS/PRS-CSx tend to have more balanced orientation\n",
    "- Scores using p-value thresholding may have systematic REF bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRS Analysis",
   "language": "python",
   "name": "prs-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
